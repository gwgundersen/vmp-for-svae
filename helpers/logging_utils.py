from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import glob
import numpy as np
import os

from tensorboard.backend.event_processing.event_accumulator import EventAccumulator


def generate_log_id(config, method_key='method', dataset_key='dataset'):
    """
    Produce a string from the experiment-configuration
    Args:
        config: dict containing parameters as keys pointing to their set values
        method_key: how to access the method run
        dataset_key: how to access the dataset on which the method is run.

    Returns:

    """
    method = config.get(method_key, 'unknownM')
    dataset = config.get(dataset_key, 'unknownD')

    log_id = '%s_%s' % (method, dataset)

    for key, val in iter(sorted(config.items())):
        if key != method_key and key != dataset_key:
            if isinstance(val, str):
                val_str = val
            elif isinstance(val, int):
                val_str = '%d' % val
            elif isinstance(val, float):
                if np.log10(np.abs(val)) >= -5:
                    val_str = '%.5f' % val
                else:
                    val_str = ('%.20f' % val).rstrip('0')
            else:
                raise NotImplementedError

            log_id += '_%s%s' % (key, val_str)

    return log_id


def get_summary(log_path, summary_tag):
    """
    Get values from summary-file saved with tensorflow
    Args:
        log_path: path to log directory generated by tensorflow
        summary_tag: name of the summary to be returned

    Returns:

    """
    steps = []
    vals = []

    for event_path in glob.glob(log_path + '/events.out.tfevents.*'):

        # load log
        ea = EventAccumulator(event_path)
        ea.Reload()

        # find tag
        tag = None
        for t in ea.Tags()['scalars']:
            if t.endswith(summary_tag):
                tag = t
                break
        if tag is None:
            raise ValueError("Inputted summary_tag '%s' does not exist for log '%s'." % (summary_tag, log_path))

        elbo = ea.Scalars(tag)

        # extract step and corresponding values
        # extract = lambda elem: (elem.step, tensor_util.MakeNdarray(elem.tensor_proto))
        extract = lambda elem: (elem.step, elem.value)

        steps_vals = list(map(extract, elbo))

        # check type of value:
        steps_vals = np.asarray(steps_vals)
        steps.append(steps_vals[:, 0].T)
        vals.append(steps_vals[:, 1].T)
        return steps, vals


def get_summaries(log_path, schedule, summary_tag):
    """
    Get the values of all summaries recorded when running schedule
    """

    # get first run
    if not os.path.exists(log_path + '/' + generate_log_id(schedule[0])):
        raise FileNotFoundError("The log-file '%s' could not be found." % generate_log_id(schedule[0]))
    steps, _ = get_summary(log_path + '/' + generate_log_id(schedule[0]), summary_tag)
    steps = steps[0]
    summaries = []

    for i, config in enumerate(schedule):
        run_path = log_path + '/' + generate_log_id(config)
        steps_, summary = get_summary(run_path, summary_tag)

        if np.array_equal(steps, steps_[0]):
            summaries.append(np.array(summary[0].reshape((1, -1))))
        else:
            print('Warning: ')

    return steps, np.vstack(summaries)


def get_summaries_np(log_path, schedule, summary_tag, generate_log_id):
    """
    Get values from .npy files
    """

    # get first run
    measurements = np.load(log_path + '/' + generate_log_id(schedule[0]), fix_imports=True, encoding='latin1')[()]
    steps = measurements['perf_meas_iters']
    summaries = []

    for i, config in enumerate(schedule):
        measurements = np.load(log_path + '/' + generate_log_id(config), fix_imports=True, encoding='latin1')[()]
        steps_ = measurements['perf_meas_iters']
        summary = measurements[summary_tag]

        if np.array_equal(steps, steps_):
            summaries.append(np.array(summary.reshape((1, -1))))
        else:
            print('Warning: ')

    return steps, np.vstack(summaries)